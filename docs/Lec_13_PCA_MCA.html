<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="copyright" content="Presentation link: https://goo.gl/8pffGO"/>
  <title>Component analysis</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <link href="site_libs/slidy-2/styles/slidy.css" rel="stylesheet" />
  <script src="site_libs/slidy-2/scripts/slidy.js"></script>
</head>
<body>
<div class="slide titlepage">
  <h1 class="title">Component analysis</h1>
  <p class="author">

  </p>
  <p class="date">25.05.2017</p>
</div>
<div id="main-problem" class="slide section level3">
<h1>1. Main problem</h1>
<p>Sometimes you have a huge amount of variables. So to make some profits from your data you need to reduce number of variables saving the information that in our data.</p>
<ul>
<li>Principal component analysis (PCA)</li>
<li>Linear discriminant analysis (LDA)</li>
<li>Multidimensional scaling (MDS)</li>
<li>…</li>
</ul>
</div>
<div id="data" class="slide section level3">
<h1>2. Data</h1>
<p>I will use a dataset from [Huttenlocher, Vasilyeva, Cymerman, Levine 2002]. Authors analysed 46 pairs of mothers and children (aged from 47 to 59 months, mean age – 54). They recorded and trinscribed 2 hours from each child day. During the study they collected number of noun phrases per utterance in mother speech to the number of noun phrases per utterance in child speech. <img src="Lec_13_PCA_MCA_files/figure-slidy/unnamed-chunk-2-1.png" width="768" /></p>
</div>
<div id="pca" class="slide section level3">
<h1>3. PCA</h1>
<p>PCA is essentially a rotation of the coordinate axes, chosen such that each successful axis captures as much variance as possible. We can reduce 2 dementions to one using a regression:</p>
<p><img src="Lec_13_PCA_MCA_files/figure-slidy/unnamed-chunk-3-1.png" width="768" /></p>
<p>We used regression for predicting value of one variable by another variable.</p>
<p><img src="Lec_13_PCA_MCA_files/figure-slidy/unnamed-chunk-4-1.png" width="768" /></p>
<p>In PCA we change coordinate system and start predicting variables’ values using less variables.</p>
<p><img src="Lec_13_PCA_MCA_files/figure-slidy/unnamed-chunk-5-1.png" width="768" /></p>
<p>So the blue line is <em>the first Princple Component</em> (and it is NOT a regression line). The number of the PCs is always equal to the number of variables. So we can draw the second PC:</p>
<p><img src="Lec_13_PCA_MCA_files/figure-slidy/unnamed-chunk-6-1.png" width="768" /></p>
<p>So the main point of PCA is that if cumulative proportion of explained variance is high we can drop some PCs. So we need know the following things:</p>
<ul>
<li>What is the cumulative proportion of explained variance?</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(<span class="kw">prcomp</span>(df))</code></pre></div>
<pre><code>## Importance of components%s:
##                           PC1    PC2
## Standard deviation     0.2544 0.1316
## Proportion of Variance 0.7890 0.2110
## Cumulative Proportion  0.7890 1.0000</code></pre>
<p>So PC1 explains only 78.9% of the variance in our data.</p>
<ul>
<li>How PCs are rotated comparing to the old axes?</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://goo.gl/Qo3Yy2&quot;</span>)
<span class="kw">prcomp</span>(df)</code></pre></div>
<pre><code>## Standard deviations (1, .., p=2):
## [1] 0.2543899 0.1315688
## 
## Rotation (n x k) = (2 x 2):
##              PC1        PC2
## child  0.6724959 -0.7401009
## mother 0.7401009  0.6724959</code></pre>
<p>So the formula for the first component rotation is <span class="math display">\[PC1 = 0.6724959 \times child + 0.7401009  \times mother\]</span> The formula for the second component rotation is <span class="math display">\[PC2 = -0.7401009 \times child + 0.6724959  \times mother\]</span></p>
<p>From now we can change the axes:</p>
<p><img src="Lec_13_PCA_MCA_files/figure-slidy/unnamed-chunk-9-1.png" width="768" /></p>
<p>The <code>autoplot()</code> function from <code>ggfortify</code> package produces nearly the same graph: <img src="Lec_13_PCA_MCA_files/figure-slidy/unnamed-chunk-10-1.png" width="768" /></p>
<p>Summary:</p>
<ul>
<li>If the cumulative proportion of explained variance for some PCs is high, we can change coordinate system and start predicting variables’ values using less variables.</li>
<li>We can even make a regresion or clusterisation model.</li>
<li>PCA for categorical variables is called Multiple correspondence analysis (MCA)</li>
</ul>
</div>
<div id="r-functions" class="slide section level3">
<h1>R functions</h1>
<p>There are several functions for PCA, MCA and their visualisation.</p>
<ul>
<li>PCA: prcomp()</li>
<li>PCA: princomp()</li>
<li>PCA: FactoMineR::PCA()</li>
<li>PCA: ade4::dudi.pca()</li>
<li>PCA: amap::acp()</li>
<li>PCA visualisation: ggfortify::autoplot</li>
<li>MCA: FactoMineR::MCA()</li>
<li>MCA: MASS::mca()</li>
<li>MCA: ade::dudi.acm()</li>
<li>MCA: ca::mjca()</li>
<li>MCA: homals::homals()</li>
</ul>
</div>

  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

</body>
</html>
